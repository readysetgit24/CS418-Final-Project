{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a model which gives better scores than the logistic regression baseline model. We will search it on the a startified sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import boto3\n",
    "\n",
    "from io import BytesIO, StringIO\n",
    "from time import perf_counter\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_BUCKET = 'sagemaker-studio-8x6b1t9vueh'\n",
    "file_name = 'df_processed2.pkl'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "preprocessed_df_ref = s3.Object(MY_BUCKET, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_process_df():\n",
    "    df = pickle.loads(preprocessed_df_ref.get()['Body'].read())\n",
    "    le = LabelEncoder()\n",
    "    val = le.fit_transform(df['Protocol'])\n",
    "    df['Protocol'] = le.fit_transform(df['Protocol']).astype('uint8')\n",
    "    # Converting Flags and Counts to uint8\n",
    "    \n",
    "    for col in df.columns:\n",
    "        dtype = str(df[col].dtypes)\n",
    "        if 'int32' in dtype:\n",
    "            df[col] = df[col].astype('uint8')\n",
    "    \n",
    "    # Convert to dummy variable.\n",
    "    df = pd.get_dummies(df, columns=['Protocol'])\n",
    "    \n",
    "    # Converting Label to Nominal Label class\n",
    "    y_label_encoder = LabelEncoder()\n",
    "    df['Label'] = y_label_encoder.fit_transform(df['Label']).astype('uint8')\n",
    "    \n",
    "    y = df['Label']\n",
    "    df.drop(columns=['Label'], inplace=True)\n",
    "    X = df\n",
    "    del df\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_and_process_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified Sampling on 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _, y, _ = train_test_split(X, y, train_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scalars_to_training_data(X_train):\n",
    "    scalers = []\n",
    "    for col in X_train.columns:\n",
    "        x = X_train[col]\n",
    "        if 'uint8' not in str(x.dtypes):\n",
    "            scaler = StandardScaler()\n",
    "            x = x.to_numpy()\n",
    "            x = scaler.fit_transform(x.reshape((-1, 1)))\n",
    "            X_train[col] = x.reshape((-1, ))\n",
    "            scalers.append(scaler)\n",
    "        else:\n",
    "            scalers.append(None)\n",
    "            \n",
    "    return scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scalars_to_validation_data(X_test, scalers):\n",
    "    for scaler, col in zip(scalers, X_test.columns):\n",
    "        if scaler is None:\n",
    "            continue\n",
    "    \n",
    "        x = X_test[col].to_numpy()\n",
    "        x = scaler.transform(x.reshape((-1, 1)))\n",
    "        X_test[col] = x.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(clf, X, y, save_models=True):\n",
    "    metrics = []\n",
    "    \n",
    "    print(f'Checking for {clf}')\n",
    "    \n",
    "    for idx, (train_index, val_index) in enumerate(kfold.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        scales = apply_scalars_to_training_data(X_train)\n",
    "        \n",
    "        start_time = perf_counter()\n",
    "        clf.fit(X_train.values, y_train.to_numpy())\n",
    "        fit_time = perf_counter()\n",
    "        \n",
    "        print(f'Fiting time {fit_time - start_time:.2f} seconds')\n",
    "        \n",
    "        X_valid, y_valid = X.iloc[val_index], y.iloc[val_index]\n",
    "        apply_scalars_to_validation_data(X_valid, scales)\n",
    "        \n",
    "        start_time = perf_counter()\n",
    "        y_pred = clf.predict(X_valid.values)\n",
    "        pred_time = perf_counter()\n",
    "        \n",
    "        print(f'Eval time {pred_time - start_time:.2f} seconds')\n",
    "        \n",
    "        metric = {'clf': deepcopy(clf)} if save_models else {}\n",
    "        \n",
    "        metrics.append({\n",
    "            **metric,\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_valid, y_pred),\n",
    "            'weighted_f1': f1_score(y_valid, y_pred, average='weighted'),\n",
    "            'macro_f1': f1_score(y_valid, y_pred, average='macro'),\n",
    "            'accuracy': accuracy_score(y_valid, y_pred)\n",
    "        })\n",
    "        \n",
    "        print(f'idx{idx} done')\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ml.m5.4xlarge (16 vCPU + 64 GiB) for faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    BaggingClassifier(n_estimators=100,  random_state=random_state, n_jobs=AUTO),\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced_subsample', random_state=random_state,\n",
    "                          n_jobs=AUTO),\n",
    "    ExtraTreesClassifier(n_estimators=100, class_weight='balanced_subsample', random_state=random_state, \n",
    "                         n_jobs=AUTO)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=100,\n",
      "                  n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False)\n",
      "Fiting time 1407.28 seconds\n",
      "Eval time 6.80 seconds\n",
      "idx0 done\n",
      "Fiting time 1542.04 seconds\n",
      "Eval time 7.09 seconds\n",
      "idx1 done\n",
      "Fiting time 1538.99 seconds\n",
      "Eval time 7.23 seconds\n",
      "idx2 done\n",
      "Fiting time 1302.25 seconds\n",
      "Eval time 7.26 seconds\n",
      "idx3 done\n",
      "Fiting time 1320.73 seconds\n",
      "Eval time 7.31 seconds\n",
      "idx4 done\n",
      "Checking for RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                       class_weight='balanced_subsample', criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       max_samples=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                       random_state=42, verbose=0, warm_start=False)\n",
      "Fiting time 143.70 seconds\n",
      "Eval time 2.22 seconds\n",
      "idx0 done\n",
      "Fiting time 143.42 seconds\n",
      "Eval time 2.22 seconds\n",
      "idx1 done\n",
      "Fiting time 138.49 seconds\n",
      "Eval time 2.22 seconds\n",
      "idx2 done\n",
      "Fiting time 148.12 seconds\n",
      "Eval time 2.22 seconds\n",
      "idx3 done\n",
      "Fiting time 153.02 seconds\n",
      "Eval time 2.22 seconds\n",
      "idx4 done\n",
      "Checking for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
      "                     class_weight='balanced_subsample', criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     max_samples=None, min_impurity_decrease=0.0,\n",
      "                     min_impurity_split=None, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                     random_state=42, verbose=0, warm_start=False)\n",
      "Fiting time 92.64 seconds\n",
      "Eval time 3.42 seconds\n",
      "idx0 done\n",
      "Fiting time 90.60 seconds\n",
      "Eval time 3.31 seconds\n",
      "idx1 done\n",
      "Fiting time 94.33 seconds\n",
      "Eval time 3.31 seconds\n",
      "idx2 done\n",
      "Fiting time 96.01 seconds\n",
      "Eval time 3.33 seconds\n",
      "idx3 done\n",
      "Fiting time 89.74 seconds\n",
      "Eval time 3.42 seconds\n",
      "idx4 done\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate(models):\n",
    "    metrics[idx] = validate_model(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [{'balanced_accuracy': 0.8635690256907828,\n",
       "   'weighted_f1': 0.9796226098877924,\n",
       "   'macro_f1': 0.8667910456986466,\n",
       "   'accuracy': 0.9830288935436176,\n",
       "   'clf': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                     max_features=1.0, max_samples=1.0, n_estimators=100,\n",
       "                     n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)},\n",
       "  {'balanced_accuracy': 0.862452733601823,\n",
       "   'weighted_f1': 0.9797398627863457,\n",
       "   'macro_f1': 0.8625041601673554,\n",
       "   'accuracy': 0.9830766387382948,\n",
       "   'clf': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                     max_features=1.0, max_samples=1.0, n_estimators=100,\n",
       "                     n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8516157635451065,\n",
       "   'weighted_f1': 0.9797081176838656,\n",
       "   'macro_f1': 0.8595215602426713,\n",
       "   'accuracy': 0.9830196525381961,\n",
       "   'clf': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                     max_features=1.0, max_samples=1.0, n_estimators=100,\n",
       "                     n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8612901286764544,\n",
       "   'weighted_f1': 0.9797505434865537,\n",
       "   'macro_f1': 0.862791061621929,\n",
       "   'accuracy': 0.9832060128141942,\n",
       "   'clf': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                     max_features=1.0, max_samples=1.0, n_estimators=100,\n",
       "                     n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)},\n",
       "  {'balanced_accuracy': 0.862639263744711,\n",
       "   'weighted_f1': 0.9796839755231198,\n",
       "   'macro_f1': 0.863191218831567,\n",
       "   'accuracy': 0.9830735584031542,\n",
       "   'clf': BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                     max_features=1.0, max_samples=1.0, n_estimators=100,\n",
       "                     n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                     warm_start=False)}],\n",
       " 1: [{'balanced_accuracy': 0.8736503990782044,\n",
       "   'weighted_f1': 0.9568706644596447,\n",
       "   'macro_f1': 0.8048912070316473,\n",
       "   'accuracy': 0.9426564810251356,\n",
       "   'clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                          class_weight='balanced_subsample', criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          max_samples=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                          random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8765850641870321,\n",
       "   'weighted_f1': 0.9550197742904198,\n",
       "   'macro_f1': 0.8072404442411497,\n",
       "   'accuracy': 0.938876909807787,\n",
       "   'clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                          class_weight='balanced_subsample', criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          max_samples=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                          random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8663441588598807,\n",
       "   'weighted_f1': 0.9564261205810553,\n",
       "   'macro_f1': 0.808126532701187,\n",
       "   'accuracy': 0.9416723139477575,\n",
       "   'clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                          class_weight='balanced_subsample', criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          max_samples=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                          random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8776818215488785,\n",
       "   'weighted_f1': 0.9550098698207541,\n",
       "   'macro_f1': 0.8022525216823921,\n",
       "   'accuracy': 0.9391279571217348,\n",
       "   'clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                          class_weight='balanced_subsample', criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          max_samples=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                          random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8726735788075609,\n",
       "   'weighted_f1': 0.955109966067416,\n",
       "   'macro_f1': 0.7994129068438934,\n",
       "   'accuracy': 0.9393158575653031,\n",
       "   'clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                          class_weight='balanced_subsample', criterion='gini',\n",
       "                          max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                          max_samples=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                          random_state=42, verbose=0, warm_start=False)}],\n",
       " 2: [{'balanced_accuracy': 0.8738499188852215,\n",
       "   'weighted_f1': 0.9578960169651565,\n",
       "   'macro_f1': 0.8478025706739515,\n",
       "   'accuracy': 0.9420558156727452,\n",
       "   'clf': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                        class_weight='balanced_subsample', criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8716083803174098,\n",
       "   'weighted_f1': 0.9575511765155461,\n",
       "   'macro_f1': 0.8420466629864318,\n",
       "   'accuracy': 0.9414382084770823,\n",
       "   'clf': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                        class_weight='balanced_subsample', criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8658787391920356,\n",
       "   'weighted_f1': 0.9573840812098267,\n",
       "   'macro_f1': 0.8415262618950243,\n",
       "   'accuracy': 0.9411424963035978,\n",
       "   'clf': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                        class_weight='balanced_subsample', criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.875403652021221,\n",
       "   'weighted_f1': 0.9574957073110842,\n",
       "   'macro_f1': 0.841721717780787,\n",
       "   'accuracy': 0.9413380975850173,\n",
       "   'clf': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                        class_weight='balanced_subsample', criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False)},\n",
       "  {'balanced_accuracy': 0.8729509120760571,\n",
       "   'weighted_f1': 0.9573320157710622,\n",
       "   'macro_f1': 0.8441047103175885,\n",
       "   'accuracy': 0.94102390340069,\n",
       "   'clf': ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                        class_weight='balanced_subsample', criterion='gini',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                        random_state=42, verbose=0, warm_start=False)}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(['Bagging Classifier', 'Random Forest Classifier', 'Extra Trees Classifier'], metrics):\n",
    "    print(f'Model {name}')\n",
    "    balanced_acc = [metric['balanced_accuracy'] for metric in metrics[model]]\n",
    "    weighted_f1 = [metric['weighted_f1'] for metric in metrics[model]]\n",
    "    macro_f1 = [metric['macro_f1'] for metric in metrics[model]]\n",
    "    accuracy = [metric['accuracy'] for metric in metrics[model]]\n",
    "    \n",
    "    print(f'Average Balanced Accuracy {sum(balanced_acc) / len(balanced_acc)}')\n",
    "    print(f'Average Weighted F1 {sum(weighted_f1) / len(weighted_f1)}')\n",
    "    print(f'Average Macro F1 {sum(macro_f1) / len(macro_f1)}')\n",
    "    print(f'Average accuracy F1 {sum(accuracy) / len(accuracy)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time order: Extra Trees (1 min 30 secs) < Random Forest (2min 20 secs) << Bagging Classifier (23+ min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Balanced Accuracy = 0.86031338305177554 (Bagging Classifier)\n",
    "\n",
    "Average Balanced Accuracy = 0.873387004496311332 (Random Forest)\n",
    "\n",
    "Average Balanced Accuracy = 0.871938320498389 (Extra Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Weighted F1 Score = 0.97970102187353544 (Bagging Classifier)\n",
    "\n",
    "Average Weighted F1 Score = 0.95568727904385798 (Random Forest)\n",
    "\n",
    "Average Weighted F1 Score = 0.95753179955453514 (Extra Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest had the highest balanced accuracy followed by Extra Trees Classifier. But the Extra Trees Classifier had a higher Weighted F1 Score and a lower training time. Therefore we go ahead with the Extra Trees Classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_filename = 'metrics.pkl'\n",
    "metrics_ref = s3.Object(MY_BUCKET, metrics_filename)\n",
    "_ = metrics_ref(body=pickle.dumps(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_and_process_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ExtraTreesClassifier(n_estimators=50, class_weight='balanced_subsample', random_state=random_state, \n",
    "                         n_jobs=AUTO),\n",
    "    ExtraTreesClassifier(n_estimators=100, class_weight='balanced_subsample', random_state=random_state, \n",
    "                         n_jobs=AUTO),\n",
    "    ExtraTreesClassifier(n_estimators=200, class_weight='balanced_subsample', random_state=random_state, \n",
    "                         n_jobs=AUTO)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
      "                     class_weight='balanced_subsample', criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     max_samples=None, min_impurity_decrease=0.0,\n",
      "                     min_impurity_split=None, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=50, n_jobs=-1, oob_score=False,\n",
      "                     random_state=42, verbose=0, warm_start=False)\n",
      "Fiting time 226.11 seconds\n",
      "Eval time 9.86 seconds\n",
      "idx0 done\n",
      "Fiting time 225.51 seconds\n",
      "Eval time 10.16 seconds\n",
      "idx1 done\n",
      "Fiting time 226.92 seconds\n",
      "Eval time 9.65 seconds\n",
      "idx2 done\n",
      "Fiting time 223.63 seconds\n",
      "Eval time 9.97 seconds\n",
      "idx3 done\n",
      "Fiting time 225.51 seconds\n",
      "Eval time 9.76 seconds\n",
      "idx4 done\n",
      "Checking for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
      "                     class_weight='balanced_subsample', criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     max_samples=None, min_impurity_decrease=0.0,\n",
      "                     min_impurity_split=None, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=100, n_jobs=-1, oob_score=False,\n",
      "                     random_state=42, verbose=0, warm_start=False)\n",
      "Fiting time 418.04 seconds\n",
      "Eval time 17.48 seconds\n",
      "idx0 done\n",
      "Fiting time 417.60 seconds\n",
      "Eval time 17.58 seconds\n",
      "idx1 done\n",
      "Fiting time 418.54 seconds\n",
      "Eval time 17.39 seconds\n",
      "idx2 done\n",
      "Fiting time 413.03 seconds\n",
      "Eval time 17.37 seconds\n",
      "idx3 done\n",
      "Fiting time 416.05 seconds\n",
      "Eval time 17.68 seconds\n",
      "idx4 done\n",
      "Checking for ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
      "                     class_weight='balanced_subsample', criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     max_samples=None, min_impurity_decrease=0.0,\n",
      "                     min_impurity_split=None, min_samples_leaf=1,\n",
      "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                     n_estimators=200, n_jobs=-1, oob_score=False,\n",
      "                     random_state=42, verbose=0, warm_start=False)\n",
      "Fiting time 815.33 seconds\n",
      "Eval time 33.11 seconds\n",
      "idx0 done\n",
      "Fiting time 813.80 seconds\n",
      "Eval time 33.91 seconds\n",
      "idx1 done\n",
      "Fiting time 814.37 seconds\n",
      "Eval time 33.11 seconds\n",
      "idx2 done\n",
      "Fiting time 808.50 seconds\n",
      "Eval time 33.41 seconds\n",
      "idx3 done\n",
      "Fiting time 806.34 seconds\n",
      "Eval time 33.53 seconds\n",
      "idx4 done\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate(models):\n",
    "    metrics[idx] = validate_model(model, X_train, y_train, save_models=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking metrics on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balanced_accuracy': 0.08333333333333333, 'weighted_f1': 0.7539450784882845, 'macro_f1': 0.07562917634907472, 'accuracy': 0.8307475973385905}\n",
      "{'balanced_accuracy': 0.08333333333333333, 'weighted_f1': 0.7539450784882845, 'macro_f1': 0.07562917634907472, 'accuracy': 0.8307475973385905}\n",
      "{'balanced_accuracy': 0.08333333333333333, 'weighted_f1': 0.7539450784882845, 'macro_f1': 0.07562917634907472, 'accuracy': 0.8307475973385905}\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metric = {\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'weighted_f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'macro_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "        'accuracy': accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking metrics on entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    metric = {\n",
    "        'balanced_accuracy': balanced_accuracy_score(y, y_pred),\n",
    "        'weighted_f1': f1_score(y, y_pred, average='weighted'),\n",
    "        'macro_f1': f1_score(y, y_pred, average='macro'),\n",
    "        'accuracy': accuracy_score(y, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved the same metrics for all the models on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ca-central-1:310906938811:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
